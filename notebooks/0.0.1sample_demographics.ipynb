{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b065ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sstats \n",
    "from statsmodels.stats import contingency_tables\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737bd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_DIR = '/Volumes/Projects_Herting/LABDOCS/Personnel/Katie/deltaABCD_clustering'\n",
    "DATA_DIR = 'data'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6dc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(PROJ_DIR, DATA_DIR, 'data.csv'), \n",
    "                 header=0, \n",
    "                 index_col='subjectkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d61731",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = [\"demo_prnt_ethn_v2\",\n",
    "                \"demo_prnt_marital_v2\",\n",
    "                \"demo_prnt_ed_v2\",\n",
    "                \"demo_comb_income_v2\",\n",
    "                \"demo_race_a_p___10\",\n",
    "                \"demo_race_a_p___11\",\n",
    "                \"demo_race_a_p___12\",\n",
    "                \"demo_race_a_p___13\",\n",
    "                \"demo_race_a_p___14\",\n",
    "                \"demo_race_a_p___15\",\n",
    "                \"demo_race_a_p___16\",\n",
    "                \"demo_race_a_p___17\",\n",
    "                \"demo_race_a_p___18\",\n",
    "                \"demo_race_a_p___19\",\n",
    "                \"demo_race_a_p___20\",\n",
    "                \"demo_race_a_p___21\",\n",
    "                \"demo_race_a_p___22\",\n",
    "                \"demo_race_a_p___23\",\n",
    "                \"demo_race_a_p___24\",\n",
    "                \"demo_race_a_p___25\",\n",
    "                \"site_id_l\",\n",
    "                \"sex\", \n",
    "                \"mri_info_manufacturer\"\n",
    "               ]\n",
    "mri_qc = [\n",
    "    \"imgincl_dmri_include\",\n",
    "    \"imgincl_rsfmri_include\",\n",
    "    \"imgincl_t1w_include\",\n",
    "    \"imgincl_t2w_include\",\n",
    "    \"interview_age\",\n",
    "    \"interview_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d46b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_and_qc = []\n",
    "for var in demographics + mri_qc:\n",
    "    demo_and_qc.append(f'{var}.baseline_year_1_arm_1')\n",
    "    if var in mri_qc:\n",
    "        demo_and_qc.append(f'{var}.2_year_follow_up_y_arm_1')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2d7fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_prnt_ethn_v2.baseline_year_1_arm_1',\n",
       " 'demo_prnt_marital_v2.baseline_year_1_arm_1',\n",
       " 'demo_prnt_ed_v2.baseline_year_1_arm_1',\n",
       " 'demo_comb_income_v2.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___10.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___11.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___12.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___13.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___14.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___15.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___16.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___17.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___18.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___19.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___20.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___21.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___22.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___23.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___24.baseline_year_1_arm_1',\n",
       " 'demo_race_a_p___25.baseline_year_1_arm_1',\n",
       " 'site_id_l.baseline_year_1_arm_1',\n",
       " 'sex.baseline_year_1_arm_1',\n",
       " 'mri_info_manufacturer.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_rsfmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_rsfmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_t1w_include.baseline_year_1_arm_1',\n",
       " 'imgincl_t1w_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_t2w_include.baseline_year_1_arm_1',\n",
       " 'imgincl_t2w_include.2_year_follow_up_y_arm_1',\n",
       " 'interview_age.baseline_year_1_arm_1',\n",
       " 'interview_age.2_year_follow_up_y_arm_1',\n",
       " 'interview_date.baseline_year_1_arm_1',\n",
       " 'interview_date.2_year_follow_up_y_arm_1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_and_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9305a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = df[demo_and_qc]\n",
    "\n",
    "#site_baseline = pd.get_dummies(demo_df, 'site_id_l.baseline_year_1_arm_1')\n",
    "#site_2yfu = pd.get_dummies(demo_df, 'site_id_l.2_year_follow_up_y_arm_1')\n",
    "\n",
    "#demo_df = pd.concat([demo_df, site_baseline, site_2yfu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2276bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34be635",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2yfu = demo_df[demo_df[\"interview_date.2_year_follow_up_y_arm_1\"].isna() == True].index\n",
    "lost_N = len(no_2yfu)\n",
    "total_N = len(demo_df.index)\n",
    "\n",
    "y2fu_df = demo_df.drop(no_2yfu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740056a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the total 11760 participants at baseline, 3958 (or 33.66%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Of the total {total_N} participants at baseline, {lost_N} (or {np.round((lost_N / total_N) *100, 2)}%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bccbf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean_base',\n",
    "                            'Age_sdev_base',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F', \n",
    "                            'Ethnicity_H', \n",
    "                            'Ethnicity_NH', \n",
    "                            'Ethnicity_refuse', \n",
    "                            'Race_White', \n",
    "                            'Race_Black', \n",
    "                            'Race_NativeAmer', \n",
    "                            'Race_AsianPac', \n",
    "                            'Race_Other', \n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse', \n",
    "                            'MRI_Siemens', \n",
    "                            'MRI_GE', \n",
    "                            'MRI_Phillips'], \n",
    "                     columns=['whole_sample', 'with_2yfu'])\n",
    "\n",
    "table.at['N', 'whole_sample'] = len(demo_df.index)\n",
    "table.at['N', 'with_2yfu'] = len(y2fu_df.index)\n",
    "\n",
    "table.at['Age_mean_base', 'whole_sample'] = np.mean(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean_base', 'with_2yfu'] = np.mean(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_mean_2yfu', 'whole_sample'] = np.mean(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_mean_2yfu', 'with_2yfu'] = np.mean(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_base', 'whole_sample'] = np.std(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev_base', 'with_2yfu'] = np.std(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_2yfu', 'whole_sample'] = np.std(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_sdev_2yfu', 'with_2yfu'] = np.std(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Sex_M', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_F', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "table.at['Ethnicity_H', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Ethnicity_H', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Ethnicity_NH', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['Ethnicity_NH', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['Ethnicity_refuse', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 777.].index)\n",
    "table.at['Ethnicity_refuse', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ethn_v2.baseline_year_1_arm_1'] == 777.].index)\n",
    "\n",
    "table.at['Race_White', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_race_a_p___10.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Race_White', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_race_a_p___10.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Race_Black', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_race_a_p___11.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Race_Black', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_race_a_p___11.baseline_year_1_arm_1'] == 1.].index)\n",
    "\n",
    "demo_df['Race_NativeAmer'] = demo_df['demo_race_a_p___12.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___13.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___14.baseline_year_1_arm_1']\n",
    "y2fu_df['Race_NativeAmer'] = y2fu_df['demo_race_a_p___12.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___13.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___14.baseline_year_1_arm_1']\n",
    "\n",
    "demo_df['Race_AsianPac'] = demo_df['demo_race_a_p___15.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___16.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___17.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___18.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___19.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___20.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___21.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___22.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___23.baseline_year_1_arm_1'] + demo_df['demo_race_a_p___24.baseline_year_1_arm_1']\n",
    "y2fu_df['Race_AsianPac'] = y2fu_df['demo_race_a_p___15.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___16.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___17.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___18.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___19.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___20.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___21.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___22.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___23.baseline_year_1_arm_1'] + y2fu_df['demo_race_a_p___24.baseline_year_1_arm_1']\n",
    "\n",
    "table.at['Race_NativeAmer', \n",
    "         'whole_sample'] = len(demo_df[demo_df['Race_NativeAmer'] > 0.].index)\n",
    "table.at['Race_NativeAmer', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['Race_NativeAmer'] > 0.].index)\n",
    "table.at['Race_AsianPac', \n",
    "         'whole_sample'] = len(demo_df[demo_df['Race_AsianPac'] > 0.].index)\n",
    "table.at['Race_AsianPac', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['Race_AsianPac'] > 0.].index)\n",
    "\n",
    "table.at['Race_Other', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_race_a_p___25.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['Race_Other', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_race_a_p___25.baseline_year_1_arm_1'] == 1.].index)\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] == 9.].index) + len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] == 10.].index)\n",
    "table.at['Income_gt100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] == 9.].index) + len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] == 10.].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'whole_sample'] = len(demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(6., 9.).index)\n",
    "table.at['Income_50to100k', \n",
    "         'with_2yfu'] = len(y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(6., 9.).index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['MRI_Siemens', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_Siemens', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1']  == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39717e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'], \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean_base', 'Stat'] = stat\n",
    "table.at['Age_mean_base', 'p(Stat)'] = pval\n",
    "\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.2_year_follow_up_y_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.2_year_follow_up_y_arm_1'].dropna())\n",
    "table.at['Age_mean_2yfu', 'Stat'] = stat\n",
    "table.at['Age_mean_2yfu', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((2,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Sex_F', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Sex_M', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Sex_F', 'with_2yfu']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,3))\n",
    "contingency[0,0] = table.loc['Ethnicity_H', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Ethnicity_NH', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Ethnicity_refuse', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Ethnicity_H', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Ethnicity_NH', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Ethnicity_refuse', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Ethnicity_H', 'Stat'] = out.statistic\n",
    "table.at['Ethnicity_H', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['Race_White', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Race_Black', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Race_NativeAmer', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Race_AsianPac', 'whole_sample']\n",
    "contingency[0,4] = table.loc['Race_Other', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Race_White', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Race_Black', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Race_NativeAmer', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Race_AsianPac', 'with_2yfu']\n",
    "contingency[1,4] = table.loc['Race_Other', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Race_White', 'Stat'] = out.statistic\n",
    "table.at['Race_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,3))\n",
    "contingency[0,0] = table.loc['MRI_Siemens', 'whole_sample']\n",
    "contingency[0,1] = table.loc['MRI_GE', 'whole_sample']\n",
    "contingency[0,2] = table.loc['MRI_Philips', 'whole_sample']\n",
    "contingency[1,0] = table.loc['MRI_Siemens', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['MRI_GE', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['MRI_Philips', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['MRI_Siemens', 'Stat'] = out.statistic\n",
    "table.at['MRI_Siemens', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1394af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_sample</th>\n",
       "      <th>with_2yfu</th>\n",
       "      <th>Stat</th>\n",
       "      <th>p(Stat)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>11760</td>\n",
       "      <td>7802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_mean_base</th>\n",
       "      <td>118.974</td>\n",
       "      <td>118.742</td>\n",
       "      <td>46695086.5</td>\n",
       "      <td>3.396358e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_sdev_base</th>\n",
       "      <td>7.49569</td>\n",
       "      <td>7.43653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_mean_2yfu</th>\n",
       "      <td>143.218</td>\n",
       "      <td>143.218</td>\n",
       "      <td>30233088.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_sdev_2yfu</th>\n",
       "      <td>7.76211</td>\n",
       "      <td>7.76211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_M</th>\n",
       "      <td>6146</td>\n",
       "      <td>4206</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>6.623282e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_F</th>\n",
       "      <td>5614</td>\n",
       "      <td>3596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethnicity_H</th>\n",
       "      <td>2023</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.678794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethnicity_NH</th>\n",
       "      <td>9666</td>\n",
       "      <td>6483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethnicity_refuse</th>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_White</th>\n",
       "      <td>8740</td>\n",
       "      <td>5980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.060058e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Black</th>\n",
       "      <td>2467</td>\n",
       "      <td>1510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_NativeAmer</th>\n",
       "      <td>427</td>\n",
       "      <td>311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_AsianPac</th>\n",
       "      <td>791</td>\n",
       "      <td>484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race_Other</th>\n",
       "      <td>795</td>\n",
       "      <td>507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_gt100k</th>\n",
       "      <td>4530</td>\n",
       "      <td>3011</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.916252e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_50to100k</th>\n",
       "      <td>11760</td>\n",
       "      <td>7802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_lt50k</th>\n",
       "      <td>3179</td>\n",
       "      <td>2029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_dkrefuse</th>\n",
       "      <td>1000</td>\n",
       "      <td>598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI_Siemens</th>\n",
       "      <td>7279</td>\n",
       "      <td>4733</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.678794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI_GE</th>\n",
       "      <td>2969</td>\n",
       "      <td>2116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI_Phillips</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI_Philips</th>\n",
       "      <td>1512</td>\n",
       "      <td>953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 whole_sample with_2yfu        Stat       p(Stat)\n",
       "N                       11760      7802         NaN           NaN\n",
       "Age_mean_base         118.974   118.742  46695086.5  3.396358e-02\n",
       "Age_sdev_base         7.49569   7.43653         NaN           NaN\n",
       "Age_mean_2yfu         143.218   143.218  30233088.0  1.000000e+00\n",
       "Age_sdev_2yfu         7.76211   7.76211         NaN           NaN\n",
       "Sex_M                    6146      4206      4206.0  6.623282e-46\n",
       "Sex_F                    5614      3596         NaN           NaN\n",
       "Ethnicity_H              2023      1287         2.0  3.678794e-01\n",
       "Ethnicity_NH             9666      6483         NaN           NaN\n",
       "Ethnicity_refuse           23        11         NaN           NaN\n",
       "Race_White               8740      5980         4.0  4.060058e-01\n",
       "Race_Black               2467      1510         NaN           NaN\n",
       "Race_NativeAmer           427       311         NaN           NaN\n",
       "Race_AsianPac             791       484         NaN           NaN\n",
       "Race_Other                795       507         NaN           NaN\n",
       "Income_gt100k            4530      3011         3.0  3.916252e-01\n",
       "Income_50to100k         11760      7802         NaN           NaN\n",
       "Income_lt50k             3179      2029         NaN           NaN\n",
       "Income_dkrefuse          1000       598         NaN           NaN\n",
       "MRI_Siemens              7279      4733         2.0  3.678794e-01\n",
       "MRI_GE                   2969      2116         NaN           NaN\n",
       "MRI_Phillips              NaN       NaN         NaN           NaN\n",
       "MRI_Philips              1512       953         NaN           NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a40f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4773809523809524"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.loc['Sex_F', 'whole_sample'] / table.loc['N', 'whole_sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddbe64c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.460907459625737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.loc['Sex_F', 'with_2yfu'] / table.loc['N', 'with_2yfu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f002c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
