{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b065ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sstats \n",
    "from statsmodels.stats import contingency_tables\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737bd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_DIR = '/Volumes/Projects_Herting/LABDOCS/Personnel/Katie/deltaABCD_clustering'\n",
    "DATA_DIR = 'data'\n",
    "OUT_DIR = 'output'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6dc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(PROJ_DIR, DATA_DIR, 'data_qcd.csv'), \n",
    "                 header=0, \n",
    "                 index_col='subjectkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d61731",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = [#\"demo_prnt_ethn_v2\",\n",
    "                \"demo_prnt_marital_v2\",\n",
    "                \"demo_prnt_ed_v2\",\n",
    "                \"demo_comb_income_v2\",\n",
    "                #\"demo_race_a_p___10\",\n",
    "                #\"demo_race_a_p___11\",\n",
    "                #\"demo_race_a_p___12\",\n",
    "                #\"demo_race_a_p___13\",\n",
    "                #\"demo_race_a_p___14\",\n",
    "                #\"demo_race_a_p___15\",\n",
    "                #\"demo_race_a_p___16\",\n",
    "                #\"demo_race_a_p___17\",\n",
    "                #\"demo_race_a_p___18\",\n",
    "                #\"demo_race_a_p___19\",\n",
    "                #\"demo_race_a_p___20\",\n",
    "                #\"demo_race_a_p___21\",\n",
    "                #\"demo_race_a_p___22\",\n",
    "                #\"demo_race_a_p___23\",\n",
    "                #\"demo_race_a_p___24\",\n",
    "                #\"demo_race_a_p___25\",\n",
    "                \"race_ethnicity\",\n",
    "                \"site_id_l\",\n",
    "                \"sex\", \n",
    "                \"mri_info_manufacturer\"\n",
    "               ]\n",
    "mri_qc = [\n",
    "    \"imgincl_dmri_include\",\n",
    "    \"imgincl_rsfmri_include\",\n",
    "    \"imgincl_t1w_include\",\n",
    "    #\"imgincl_t2w_include\",\n",
    "    \"mrif_score\",\n",
    "    \"interview_age\",\n",
    "    \"interview_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d46b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_and_qc = []\n",
    "for var in demographics + mri_qc:\n",
    "    demo_and_qc.append(f'{var}.baseline_year_1_arm_1')\n",
    "    if var in mri_qc:\n",
    "        demo_and_qc.append(f'{var}.2_year_follow_up_y_arm_1')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2d7fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_prnt_marital_v2.baseline_year_1_arm_1',\n",
       " 'demo_prnt_ed_v2.baseline_year_1_arm_1',\n",
       " 'demo_comb_income_v2.baseline_year_1_arm_1',\n",
       " 'race_ethnicity.baseline_year_1_arm_1',\n",
       " 'site_id_l.baseline_year_1_arm_1',\n",
       " 'sex.baseline_year_1_arm_1',\n",
       " 'mri_info_manufacturer.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_rsfmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_rsfmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_t1w_include.baseline_year_1_arm_1',\n",
       " 'imgincl_t1w_include.2_year_follow_up_y_arm_1',\n",
       " 'mrif_score.baseline_year_1_arm_1',\n",
       " 'mrif_score.2_year_follow_up_y_arm_1',\n",
       " 'interview_age.baseline_year_1_arm_1',\n",
       " 'interview_age.2_year_follow_up_y_arm_1',\n",
       " 'interview_date.baseline_year_1_arm_1',\n",
       " 'interview_date.2_year_follow_up_y_arm_1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_and_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9305a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = df[demo_and_qc]\n",
    "\n",
    "#site_baseline = pd.get_dummies(demo_df, 'site_id_l.baseline_year_1_arm_1')\n",
    "#site_2yfu = pd.get_dummies(demo_df, 'site_id_l.2_year_follow_up_y_arm_1')\n",
    "\n",
    "#demo_df = pd.concat([demo_df, site_baseline, site_2yfu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2276bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34be635",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2yfu = demo_df[demo_df[\"interview_date.2_year_follow_up_y_arm_1\"].isna() == True].index\n",
    "lost_N = len(no_2yfu)\n",
    "total_N = len(demo_df.index)\n",
    "\n",
    "y2fu_df = demo_df.drop(no_2yfu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740056a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the total 7457 participants at baseline, 0 (or 0.0%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Of the total {total_N} participants at baseline, {lost_N} (or {np.round((lost_N / total_N) *100, 2)}%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bccbf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean_base',\n",
    "                            'Age_sdev_base',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F', \n",
    "                            'RE_Black',\n",
    "                            'RE_White',\n",
    "                            'RE_Hispanic',\n",
    "                            'RE_Asian',\n",
    "                            'RE_Other',\n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse',\n",
    "                            'Marital_Married',\n",
    "                            'Marital_Widowed',\n",
    "                            'Marital_Divorced',\n",
    "                            'Marital_Separated',\n",
    "                            'Marital_Never',\n",
    "                            'Marital_Refused',\n",
    "                            'Education_ltHS',\n",
    "                            'Education_HSGED',\n",
    "                            'Education_SomeCol',\n",
    "                            'Education_AA',\n",
    "                            'Education_Bachelors',\n",
    "                            'Education_Graduate',\n",
    "                            'MRI_Siemens', \n",
    "                            'MRI_GE', \n",
    "                            'MRI_Phillips'], \n",
    "                     columns=['whole_sample', 'with_2yfu'])\n",
    "\n",
    "table.at['N', 'whole_sample'] = len(demo_df.index)\n",
    "table.at['N', 'with_2yfu'] = len(y2fu_df.index)\n",
    "\n",
    "table.at['Age_mean_base', 'whole_sample'] = np.mean(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean_base', 'with_2yfu'] = np.mean(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_mean_2yfu', 'whole_sample'] = np.mean(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_mean_2yfu', 'with_2yfu'] = np.mean(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_base', 'whole_sample'] = np.std(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev_base', 'with_2yfu'] = np.std(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_2yfu', 'whole_sample'] = np.std(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_sdev_2yfu', 'with_2yfu'] = np.std(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Sex_M', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_F', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "\n",
    "table.at['RE_White', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_Black', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['MRI_Siemens', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_Siemens', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1']  == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "\n",
    "table.at['Marital_Married', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Widowed', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Divorced', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Separated', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Never', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Refused', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_uptoHSGED', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39717e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'].dropna())\n",
    "table.at['Age_mean_base', 'Stat'] = stat\n",
    "table.at['Age_mean_base', 'p(Stat)'] = pval\n",
    "\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.2_year_follow_up_y_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.2_year_follow_up_y_arm_1'].dropna())\n",
    "table.at['Age_mean_2yfu', 'Stat'] = stat\n",
    "table.at['Age_mean_2yfu', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((2,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Sex_F', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Sex_M', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Sex_F', 'with_2yfu']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['RE_White', 'whole_sample']\n",
    "contingency[0,1] = table.loc['RE_Black', 'whole_sample']\n",
    "contingency[0,2] = table.loc['RE_Hispanic', 'whole_sample']\n",
    "contingency[0,3] = table.loc['RE_AsianOther', 'whole_sample']\n",
    "contingency[1,0] = table.loc['RE_White', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['RE_Black', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['RE_Hispanic', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['RE_AsianOther', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['RE_White', 'Stat'] = out.statistic\n",
    "table.at['RE_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,3))\n",
    "contingency[0,0] = table.loc['MRI_Siemens', 'whole_sample']\n",
    "contingency[0,1] = table.loc['MRI_GE', 'whole_sample']\n",
    "contingency[0,2] = table.loc['MRI_Philips', 'whole_sample']\n",
    "contingency[1,0] = table.loc['MRI_Siemens', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['MRI_GE', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['MRI_Philips', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['MRI_Siemens', 'Stat'] = out.statistic\n",
    "table.at['MRI_Siemens', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['Marital_Married', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Marital_Widowed', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Marital_Divorced', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Marital_Separated', 'whole_sample']\n",
    "contingency[0,4] = table.loc['Marital_Never', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Marital_Married', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Marital_Widowed', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Marital_Divorced', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Marital_Separated', 'with_2yfu']\n",
    "contingency[1,4] = table.loc['Marital_Never', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Marital_Married', 'Stat'] = out.statistic\n",
    "table.at['Marital_Married', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Education_uptoHSGED', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Education_SomeColAA', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Education_Bachelors', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Education_Graduate', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Education_uptoHSGED', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Education_SomeColAA', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Education_Bachelors', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Education_Graduate', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Education_uptoHSGED', 'Stat'] = out.statistic\n",
    "table.at['Education_uptoHSGED', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c2e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(join(PROJ_DIR, OUT_DIR, 'sample_demographics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a40f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same thing for Siemens vs. GE vs. Philips\n",
    "\n",
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean',\n",
    "                            'Age_sdev',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F',\n",
    "                            'Puberty',\n",
    "                            'RE_Black',\n",
    "                            'RE_White',\n",
    "                            'RE_Hispanic',\n",
    "                            'RE_Asian',\n",
    "                            'RE_Other',\n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse',\n",
    "                            'Marital_Married',\n",
    "                            'Marital_Widowed',\n",
    "                            'Marital_Divorced',\n",
    "                            'Marital_Separated',\n",
    "                            'Marital_Never',\n",
    "                            'Marital_Refused',\n",
    "                            'Education_ltHS',\n",
    "                            'Education_HSGED',\n",
    "                            'Education_SomeCol',\n",
    "                            'Education_AA',\n",
    "                            'Education_Bachelors',\n",
    "                            'Education_Graduate'], \n",
    "                     columns=['siemens', 'philips', 'ge'])\n",
    "\n",
    "philips_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"]\n",
    "siemens_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"]\n",
    "ge_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"]\n",
    "\n",
    "\n",
    "table.at['N', 'philips'] = len(philips_df.index)\n",
    "table.at['N', 'siemens'] = len(siemens_df.index)\n",
    "table.at['N', 'ge'] = len(ge_df.index)\n",
    "\n",
    "table.at['Age_mean', 'philips'] = np.mean(philips_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean', 'siemens'] = np.mean(siemens_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean', 'ge'] = np.mean(ge_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev', 'philips'] = np.std(philips_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev', 'siemens'] = np.std(siemens_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev', 'ge'] = np.std(ge_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "\n",
    "table.at['Sex_M', 'philips'] = len(philips_df[philips_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'siemens'] = len(siemens_df[siemens_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'ge'] = len(ge_df[ge_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "\n",
    "table.at['Sex_F', 'philips'] = len(philips_df[philips_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'siemens'] = len(siemens_df[siemens_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'ge'] = len(ge_df[ge_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "\n",
    "table.at['RE_White', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_Black', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "\n",
    "table.at['RE_Hispanic', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "\n",
    "table.at['RE_AsianOther', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['Marital_Married', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "\n",
    "table.at['Marital_Widowed', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "\n",
    "table.at['Marital_Divorced', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "\n",
    "table.at['Marital_Separated', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "\n",
    "table.at['Marital_Never', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "\n",
    "table.at['Marital_Refused', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_uptoHSGED', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddbe64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'].dropna())\n",
    "table.at['Age_mean', 'Stat'] = stat\n",
    "table.at['Age_mean', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((3,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'philips']\n",
    "contingency[0,1] = table.loc['Sex_F', 'philips']\n",
    "contingency[1,0] = table.loc['Sex_M', 'siemens']\n",
    "contingency[1,1] = table.loc['Sex_F', 'siemens']\n",
    "contingency[2,0] = table.loc['Sex_M', 'ge']\n",
    "contingency[2,1] = table.loc['Sex_F', 'ge']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['RE_White', 'philips']\n",
    "contingency[0,1] = table.loc['RE_Black', 'philips']\n",
    "contingency[0,2] = table.loc['RE_Hispanic', 'philips']\n",
    "contingency[0,3] = table.loc['RE_AsianOther', 'philips']\n",
    "contingency[1,0] = table.loc['RE_White', 'siemens']\n",
    "contingency[1,1] = table.loc['RE_Black', 'siemens']\n",
    "contingency[1,2] = table.loc['RE_Hispanic', 'siemens']\n",
    "contingency[1,3] = table.loc['RE_AsianOther', 'siemens']\n",
    "contingency[2,0] = table.loc['RE_White', 'ge']\n",
    "contingency[2,1] = table.loc['RE_Black', 'ge']\n",
    "contingency[2,2] = table.loc['RE_Hispanic', 'ge']\n",
    "contingency[2,3] = table.loc['RE_AsianOther', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['RE_White', 'Stat'] = out.statistic\n",
    "table.at['RE_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'philips']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'philips']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'philips']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'philips']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'siemens']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'siemens']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'siemens']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'siemens']\n",
    "contingency[2,0] = table.loc['Income_gt100k', 'ge']\n",
    "contingency[2,1] = table.loc['Income_50to100k', 'ge']\n",
    "contingency[2,2] = table.loc['Income_lt50k', 'ge']\n",
    "contingency[2,3] = table.loc['Income_dkrefuse', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((3,5))\n",
    "contingency[0,0] = table.loc['Marital_Married', 'philips']\n",
    "contingency[0,1] = table.loc['Marital_Widowed', 'philips']\n",
    "contingency[0,2] = table.loc['Marital_Divorced', 'philips']\n",
    "contingency[0,3] = table.loc['Marital_Separated', 'philips']\n",
    "contingency[0,4] = table.loc['Marital_Never', 'philips']\n",
    "contingency[1,0] = table.loc['Marital_Married', 'siemens']\n",
    "contingency[1,1] = table.loc['Marital_Widowed', 'siemens']\n",
    "contingency[1,2] = table.loc['Marital_Divorced', 'siemens']\n",
    "contingency[1,3] = table.loc['Marital_Separated', 'siemens']\n",
    "contingency[1,4] = table.loc['Marital_Never', 'siemens']\n",
    "contingency[2,0] = table.loc['Marital_Married', 'ge']\n",
    "contingency[2,1] = table.loc['Marital_Widowed', 'ge']\n",
    "contingency[2,2] = table.loc['Marital_Divorced', 'ge']\n",
    "contingency[2,3] = table.loc['Marital_Separated', 'ge']\n",
    "contingency[2,4] = table.loc['Marital_Never', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Marital_Married', 'Stat'] = out.statistic\n",
    "table.at['Marital_Married', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['Education_uptoHSGED', 'philips']\n",
    "contingency[0,1] = table.loc['Education_SomeColAA', 'philips']\n",
    "contingency[0,2] = table.loc['Education_Bachelors', 'philips']\n",
    "contingency[0,3] = table.loc['Education_Graduate', 'philips']\n",
    "contingency[1,0] = table.loc['Education_uptoHSGED', 'siemens']\n",
    "contingency[1,1] = table.loc['Education_SomeColAA', 'siemens']\n",
    "contingency[1,2] = table.loc['Education_Bachelors', 'siemens']\n",
    "contingency[1,3] = table.loc['Education_Graduate', 'siemens']\n",
    "contingency[2,0] = table.loc['Education_uptoHSGED', 'ge']\n",
    "contingency[2,1] = table.loc['Education_SomeColAA', 'ge']\n",
    "contingency[2,2] = table.loc['Education_Bachelors', 'ge']\n",
    "contingency[2,3] = table.loc['Education_Graduate', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Education_uptoHSGED', 'Stat'] = out.statistic\n",
    "table.at['Education_uptoHSGED', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec36d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siemens</th>\n",
       "      <th>philips</th>\n",
       "      <th>ge</th>\n",
       "      <th>Stat</th>\n",
       "      <th>p(Stat)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>4539</td>\n",
       "      <td>905</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_mean</th>\n",
       "      <td>119.079779</td>\n",
       "      <td>118.891232</td>\n",
       "      <td>117.916998</td>\n",
       "      <td>27661922.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_sdev</th>\n",
       "      <td>7.378814</td>\n",
       "      <td>7.271441</td>\n",
       "      <td>7.592738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_M</th>\n",
       "      <td>2479</td>\n",
       "      <td>488</td>\n",
       "      <td>1053</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_F</th>\n",
       "      <td>2060</td>\n",
       "      <td>417</td>\n",
       "      <td>960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE_Black</th>\n",
       "      <td>694</td>\n",
       "      <td>109</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE_White</th>\n",
       "      <td>2634</td>\n",
       "      <td>545</td>\n",
       "      <td>929</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.391625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE_Hispanic</th>\n",
       "      <td>746</td>\n",
       "      <td>158</td>\n",
       "      <td>546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_gt100k</th>\n",
       "      <td>1765</td>\n",
       "      <td>398</td>\n",
       "      <td>713</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.391625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_50to100k</th>\n",
       "      <td>1340</td>\n",
       "      <td>243</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_lt50k</th>\n",
       "      <td>1113</td>\n",
       "      <td>182</td>\n",
       "      <td>627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_dkrefuse</th>\n",
       "      <td>321</td>\n",
       "      <td>82</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Married</th>\n",
       "      <td>3185</td>\n",
       "      <td>658</td>\n",
       "      <td>1349</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.406006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Widowed</th>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Divorced</th>\n",
       "      <td>381</td>\n",
       "      <td>76</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Separated</th>\n",
       "      <td>145</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Never</th>\n",
       "      <td>545</td>\n",
       "      <td>86</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Refused</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <td>1400</td>\n",
       "      <td>265</td>\n",
       "      <td>539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_Graduate</th>\n",
       "      <td>1060</td>\n",
       "      <td>303</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RE_AsianOther</th>\n",
       "      <td>465</td>\n",
       "      <td>93</td>\n",
       "      <td>360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_uptoHSGED</th>\n",
       "      <td>650</td>\n",
       "      <td>136</td>\n",
       "      <td>361</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.391625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_SomeColAA</th>\n",
       "      <td>1422</td>\n",
       "      <td>200</td>\n",
       "      <td>611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        siemens     philips          ge        Stat   p(Stat)\n",
       "N                          4539         905        2013         NaN       NaN\n",
       "Age_mean             119.079779  118.891232  117.916998  27661922.0  1.000000\n",
       "Age_sdev               7.378814    7.271441    7.592738         NaN       NaN\n",
       "Sex_M                      2479         488        1053       417.0  0.000000\n",
       "Sex_F                      2060         417         960         NaN       NaN\n",
       "RE_Black                    694         109         178         NaN       NaN\n",
       "RE_White                   2634         545         929         3.0  0.391625\n",
       "RE_Hispanic                 746         158         546         NaN       NaN\n",
       "Income_gt100k              1765         398         713         3.0  0.391625\n",
       "Income_50to100k            1340         243         499         NaN       NaN\n",
       "Income_lt50k               1113         182         627         NaN       NaN\n",
       "Income_dkrefuse             321          82         174         NaN       NaN\n",
       "Marital_Married            3185         658        1349         4.0  0.406006\n",
       "Marital_Widowed              38           6          16         NaN       NaN\n",
       "Marital_Divorced            381          76         202         NaN       NaN\n",
       "Marital_Separated           145          28          89         NaN       NaN\n",
       "Marital_Never               545          86         219         NaN       NaN\n",
       "Marital_Refused              19           6          18         NaN       NaN\n",
       "Education_Bachelors        1400         265         539         NaN       NaN\n",
       "Education_Graduate         1060         303         500         NaN       NaN\n",
       "RE_AsianOther               465          93         360         NaN       NaN\n",
       "Education_uptoHSGED         650         136         361         3.0  0.391625\n",
       "Education_SomeColAA        1422         200         611         NaN       NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b28ba7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(join(PROJ_DIR, OUT_DIR, 'demographic_differences_between_scanners.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de277b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
