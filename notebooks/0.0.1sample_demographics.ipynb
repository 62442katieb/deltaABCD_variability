{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b065ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sstats \n",
    "from statsmodels.stats import contingency_tables\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737bd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_DIR = '/Volumes/Projects_Herting/LABDOCS/Personnel/Katie/deltaABCD_clustering'\n",
    "DATA_DIR = 'data'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6dc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(PROJ_DIR, DATA_DIR, 'data_qcd.csv'), \n",
    "                 header=0, \n",
    "                 index_col='subjectkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d61731",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = [#\"demo_prnt_ethn_v2\",\n",
    "                \"demo_prnt_marital_v2\",\n",
    "                \"demo_prnt_ed_v2\",\n",
    "                \"demo_comb_income_v2\",\n",
    "                #\"demo_race_a_p___10\",\n",
    "                #\"demo_race_a_p___11\",\n",
    "                #\"demo_race_a_p___12\",\n",
    "                #\"demo_race_a_p___13\",\n",
    "                #\"demo_race_a_p___14\",\n",
    "                #\"demo_race_a_p___15\",\n",
    "                #\"demo_race_a_p___16\",\n",
    "                #\"demo_race_a_p___17\",\n",
    "                #\"demo_race_a_p___18\",\n",
    "                #\"demo_race_a_p___19\",\n",
    "                #\"demo_race_a_p___20\",\n",
    "                #\"demo_race_a_p___21\",\n",
    "                #\"demo_race_a_p___22\",\n",
    "                #\"demo_race_a_p___23\",\n",
    "                #\"demo_race_a_p___24\",\n",
    "                #\"demo_race_a_p___25\",\n",
    "                \"race_ethnicity\",\n",
    "                \"site_id_l\",\n",
    "                \"sex\", \n",
    "                \"mri_info_manufacturer\"\n",
    "               ]\n",
    "mri_qc = [\n",
    "    \"imgincl_dmri_include\",\n",
    "    \"imgincl_rsfmri_include\",\n",
    "    \"imgincl_t1w_include\",\n",
    "    #\"imgincl_t2w_include\",\n",
    "    \"mrif_score\",\n",
    "    \"interview_age\",\n",
    "    \"interview_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d46b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_and_qc = []\n",
    "for var in demographics + mri_qc:\n",
    "    demo_and_qc.append(f'{var}.baseline_year_1_arm_1')\n",
    "    if var in mri_qc:\n",
    "        demo_and_qc.append(f'{var}.2_year_follow_up_y_arm_1')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2d7fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_prnt_marital_v2.baseline_year_1_arm_1',\n",
       " 'demo_prnt_ed_v2.baseline_year_1_arm_1',\n",
       " 'demo_comb_income_v2.baseline_year_1_arm_1',\n",
       " 'race_ethnicity.baseline_year_1_arm_1',\n",
       " 'site_id_l.baseline_year_1_arm_1',\n",
       " 'sex.baseline_year_1_arm_1',\n",
       " 'mri_info_manufacturer.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_dmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_rsfmri_include.baseline_year_1_arm_1',\n",
       " 'imgincl_rsfmri_include.2_year_follow_up_y_arm_1',\n",
       " 'imgincl_t1w_include.baseline_year_1_arm_1',\n",
       " 'imgincl_t1w_include.2_year_follow_up_y_arm_1',\n",
       " 'mrif_score.baseline_year_1_arm_1',\n",
       " 'mrif_score.2_year_follow_up_y_arm_1',\n",
       " 'interview_age.baseline_year_1_arm_1',\n",
       " 'interview_age.2_year_follow_up_y_arm_1',\n",
       " 'interview_date.baseline_year_1_arm_1',\n",
       " 'interview_date.2_year_follow_up_y_arm_1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_and_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9305a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = df[demo_and_qc]\n",
    "\n",
    "#site_baseline = pd.get_dummies(demo_df, 'site_id_l.baseline_year_1_arm_1')\n",
    "#site_2yfu = pd.get_dummies(demo_df, 'site_id_l.2_year_follow_up_y_arm_1')\n",
    "\n",
    "#demo_df = pd.concat([demo_df, site_baseline, site_2yfu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2276bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c34be635",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2yfu = demo_df[demo_df[\"interview_date.2_year_follow_up_y_arm_1\"].isna() == True].index\n",
    "lost_N = len(no_2yfu)\n",
    "total_N = len(demo_df.index)\n",
    "\n",
    "y2fu_df = demo_df.drop(no_2yfu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740056a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the total 7457 participants at baseline, 0 (or 0.0%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Of the total {total_N} participants at baseline, {lost_N} (or {np.round((lost_N / total_N) *100, 2)}%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bccbf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean_base',\n",
    "                            'Age_sdev_base',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F', \n",
    "                            'RE_Black',\n",
    "                            'RE_White',\n",
    "                            'RE_Hispanic',\n",
    "                            'RE_Asian',\n",
    "                            'RE_Other',\n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse',\n",
    "                            'Marital_Married',\n",
    "                            'Marital_Widowed',\n",
    "                            'Marital_Divorced',\n",
    "                            'Marital_Separated',\n",
    "                            'Marital_Never',\n",
    "                            'Marital_Refused',\n",
    "                            'Education_ltHS',\n",
    "                            'Education_HSGED',\n",
    "                            'Education_SomeCol',\n",
    "                            'Education_AA',\n",
    "                            'Education_Bachelors',\n",
    "                            'Education_Graduate',\n",
    "                            'MRI_Siemens', \n",
    "                            'MRI_GE', \n",
    "                            'MRI_Phillips'], \n",
    "                     columns=['whole_sample', 'with_2yfu'])\n",
    "\n",
    "table.at['N', 'whole_sample'] = len(demo_df.index)\n",
    "table.at['N', 'with_2yfu'] = len(y2fu_df.index)\n",
    "\n",
    "table.at['Age_mean_base', 'whole_sample'] = np.mean(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean_base', 'with_2yfu'] = np.mean(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_mean_2yfu', 'whole_sample'] = np.mean(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_mean_2yfu', 'with_2yfu'] = np.mean(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_base', 'whole_sample'] = np.std(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev_base', 'with_2yfu'] = np.std(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_2yfu', 'whole_sample'] = np.std(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_sdev_2yfu', 'with_2yfu'] = np.std(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Sex_M', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_F', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "\n",
    "table.at['RE_White', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_Black', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['MRI_Siemens', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_Siemens', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1']  == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "\n",
    "table.at['Marital_Married', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Widowed', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Divorced', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Separated', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Never', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Refused', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_uptoHSGED', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39717e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katherine.b/Library/Python/3.8/lib/python/site-packages/statsmodels/stats/contingency_tables.py:1405: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  q_stat = ((k-1) * (k * np.sum(count_col_success**2) - count_col_ss**2)\n"
     ]
    }
   ],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'].dropna())\n",
    "table.at['Age_mean_base', 'Stat'] = stat\n",
    "table.at['Age_mean_base', 'p(Stat)'] = pval\n",
    "\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.2_year_follow_up_y_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.2_year_follow_up_y_arm_1'].dropna())\n",
    "table.at['Age_mean_2yfu', 'Stat'] = stat\n",
    "table.at['Age_mean_2yfu', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((2,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Sex_F', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Sex_M', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Sex_F', 'with_2yfu']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['RE_White', 'whole_sample']\n",
    "contingency[0,1] = table.loc['RE_Black', 'whole_sample']\n",
    "contingency[0,2] = table.loc['RE_Hispanic', 'whole_sample']\n",
    "contingency[0,3] = table.loc['RE_Asian', 'whole_sample']\n",
    "contingency[0,4] = table.loc['RE_Other', 'whole_sample']\n",
    "contingency[1,0] = table.loc['RE_White', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['RE_Black', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['RE_Hispanic', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['RE_Asian', 'with_2yfu']\n",
    "contingency[1,4] = table.loc['RE_Other', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['RE_White', 'Stat'] = out.statistic\n",
    "table.at['RE_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,3))\n",
    "contingency[0,0] = table.loc['MRI_Siemens', 'whole_sample']\n",
    "contingency[0,1] = table.loc['MRI_GE', 'whole_sample']\n",
    "contingency[0,2] = table.loc['MRI_Philips', 'whole_sample']\n",
    "contingency[1,0] = table.loc['MRI_Siemens', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['MRI_GE', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['MRI_Philips', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['MRI_Siemens', 'Stat'] = out.statistic\n",
    "table.at['MRI_Siemens', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['Marital_Married', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Marital_Widowed', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Marital_Divorced', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Marital_Separated', 'whole_sample']\n",
    "contingency[0,4] = table.loc['Marital_Never', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Marital_Married', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Marital_Widowed', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Marital_Divorced', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Marital_Separated', 'with_2yfu']\n",
    "contingency[1,4] = table.loc['Marital_Never', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Marital_Married', 'Stat'] = out.statistic\n",
    "table.at['Marital_Married', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Education_uptoHSGED', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Education_SomeColAA', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Education_Bachelors', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Education_Graduate', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Education_uptoHSGED', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Education_SomeColAA', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Education_Bachelors', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Education_Graduate', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Education_ltHS', 'Stat'] = out.statistic\n",
    "table.at['Education_ltHS', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa094dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a40f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.loc['Sex_F', 'whole_sample'] / table.loc['N', 'whole_sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.loc['Sex_F', 'with_2yfu'] / table.loc['N', 'with_2yfu']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
