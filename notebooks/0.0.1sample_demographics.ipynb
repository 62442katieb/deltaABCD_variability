{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b065ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sstats \n",
    "from statsmodels.stats import contingency_tables\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737bd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_DIR = '/Volumes/Projects_Herting/LABDOCS/Personnel/Katie/deltaABCD_clustering'\n",
    "DATA_DIR = 'data'\n",
    "OUT_DIR = 'output'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6dc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(PROJ_DIR, DATA_DIR, 'data_qcd.csv'), \n",
    "                 header=0, \n",
    "                 index_col='subjectkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda9335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check to see if any site had MRIs made by different manufacturers\n",
    "\n",
    "for site in df['site_id_l.baseline_year_1_arm_1'].unique():\n",
    "    temp = df[df['site_id_l.baseline_year_1_arm_1'] == site]\n",
    "    print(len(temp['mri_info_manufacturer.baseline_year_1_arm_1'].unique()))\n",
    "for site in df['site_id_l.2_year_follow_up_y_arm_1'].unique():\n",
    "    temp = df[df['site_id_l.2_year_follow_up_y_arm_1'] == site]\n",
    "    print(len(temp['mri_info_manufacturer.2_year_follow_up_y_arm_1'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d61731",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = [#\"demo_prnt_ethn_v2\",\n",
    "                \"demo_prnt_marital_v2\",\n",
    "                \"demo_prnt_ed_v2\",\n",
    "                \"demo_comb_income_v2\",\n",
    "                #\"demo_race_a_p___10\",\n",
    "                #\"demo_race_a_p___11\",\n",
    "                #\"demo_race_a_p___12\",\n",
    "                #\"demo_race_a_p___13\",\n",
    "                #\"demo_race_a_p___14\",\n",
    "                #\"demo_race_a_p___15\",\n",
    "                #\"demo_race_a_p___16\",\n",
    "                #\"demo_race_a_p___17\",\n",
    "                #\"demo_race_a_p___18\",\n",
    "                #\"demo_race_a_p___19\",\n",
    "                #\"demo_race_a_p___20\",\n",
    "                #\"demo_race_a_p___21\",\n",
    "                #\"demo_race_a_p___22\",\n",
    "                #\"demo_race_a_p___23\",\n",
    "                #\"demo_race_a_p___24\",\n",
    "                #\"demo_race_a_p___25\",\n",
    "                \"race_ethnicity\",\n",
    "                \"site_id_l\",\n",
    "                \"sex\", \n",
    "                \"mri_info_manufacturer\"\n",
    "               ]\n",
    "mri_qc = [\n",
    "    \"imgincl_dmri_include\",\n",
    "    \"imgincl_rsfmri_include\",\n",
    "    \"imgincl_t1w_include\",\n",
    "    #\"imgincl_t2w_include\",\n",
    "    \"mrif_score\",\n",
    "    \"interview_age\",\n",
    "    \"interview_date\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68ad4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for site in df['site_id_l.2_year_follow_up_y_arm_1'].unique():\n",
    "    temp = df[df['site_id_l.2_year_follow_up_y_arm_1'] == site]\n",
    "    print(len(temp['mri_info_manufacturer.2_year_follow_up_y_arm_1'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d46b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_and_qc = []\n",
    "for var in demographics + mri_qc:\n",
    "    demo_and_qc.append(f'{var}.baseline_year_1_arm_1')\n",
    "    if var in mri_qc:\n",
    "        demo_and_qc.append(f'{var}.2_year_follow_up_y_arm_1')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c2d7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_and_qc\n",
    "demo_df = df[demo_and_qc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9305a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#site_baseline = pd.get_dummies(demo_df, 'site_id_l.baseline_year_1_arm_1')\n",
    "#site_2yfu = pd.get_dummies(demo_df, 'site_id_l.2_year_follow_up_y_arm_1')\n",
    "\n",
    "#demo_df = pd.concat([demo_df, site_baseline, site_2yfu], axis=1)\n",
    "\n",
    "scanner_dummies = pd.get_dummies(demo_df['mri_info_manufacturer.baseline_year_1_arm_1'])\n",
    "scanner_dummies['SIEMENS'] = scanner_dummies['SIEMENS'] * 2\n",
    "scanner_dummies['GE MEDICAL SYSTEMS'] = scanner_dummies['GE MEDICAL SYSTEMS'] * 3\n",
    "scanner = scanner_dummies.sum(axis=1)\n",
    "scanner.name = 'scanner'\n",
    "sex_dummies = pd.get_dummies(demo_df['sex.baseline_year_1_arm_1'])\n",
    "#site_dummies = pd.get_dummies(demo_df['site_id_l.baseline_year_1_arm_1'])\n",
    "puberty = df[['pds_p_ss_female_category_2.baseline_year_1_arm_1',\n",
    "              'pds_p_ss_male_category_2.baseline_year_1_arm_1']].sum(axis=1)\n",
    "puberty.name = 'puberty'\n",
    "\n",
    "collinearity_vars = ['demo_prnt_marital_v2.baseline_year_1_arm_1',\n",
    "    'demo_prnt_ed_v2.baseline_year_1_arm_1',\n",
    "    'demo_comb_income_v2.baseline_year_1_arm_1',\n",
    "    'race_ethnicity.baseline_year_1_arm_1',\n",
    "    'interview_age.baseline_year_1_arm_1',\n",
    " ]\n",
    "\n",
    "\n",
    "coll_df = pd.concat([demo_df[collinearity_vars], scanner, sex_dummies, puberty], axis=1)\n",
    "#coll_df = coll_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2276bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c34be635",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_2yfu = demo_df[demo_df[\"interview_date.2_year_follow_up_y_arm_1\"].isna() == True].index\n",
    "lost_N = len(no_2yfu)\n",
    "total_N = len(demo_df.index)\n",
    "\n",
    "y2fu_df = demo_df.drop(no_2yfu, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb2131e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_prnt_marital_v2.baseline_year_1_arm_1 1.010058234478449\n",
      "demo_prnt_ed_v2.baseline_year_1_arm_1 1.0026610465655676\n",
      "demo_comb_income_v2.baseline_year_1_arm_1 1.016945956946739\n",
      "race_ethnicity.baseline_year_1_arm_1 1.0351798143885975\n",
      "interview_age.baseline_year_1_arm_1 1.0409534416722457\n",
      "scanner 1.020004086968487\n",
      "F 127.90903696909427\n",
      "M 151.61447349725864\n",
      "puberty 1.289998381565279\n",
      "\n",
      "\n",
      "Paper 1 variables:\n",
      "\n",
      "F 2.29\n",
      "interview_age.baseline_year_1_arm_1 4.53\n",
      "puberty 5.61\n"
     ]
    }
   ],
   "source": [
    "# check collinearity between variables\n",
    "\n",
    "for i in range(0, len(coll_df.columns)):\n",
    "    vif = variance_inflation_factor(coll_df.dropna().values, i)\n",
    "    print(coll_df.columns[i], vif)\n",
    "\n",
    "# now separately for just age, sex, and puberty\n",
    "print('\\n\\nPaper 1 variables:\\n')\n",
    "paper1_vars = ['F', 'interview_age.baseline_year_1_arm_1', 'puberty']\n",
    "for i in range(0, 3):\n",
    "    vif = variance_inflation_factor(coll_df[paper1_vars].dropna().values, i)\n",
    "    print(paper1_vars[i], np.round(vif, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b993f535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prodcuct moment correlation for demo_prnt_marital_v2.baseline_year_1_arm_1 and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.013 0.24466\n",
      "Prodcuct moment correlation for demo_prnt_marital_v2.baseline_year_1_arm_1 and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.086 0.0\n",
      "Spearman r for demo_prnt_marital_v2.baseline_year_1_arm_1 and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.25693976134628077 9.812102548232799e-113\n",
      "Prodcuct moment correlation for demo_prnt_marital_v2.baseline_year_1_arm_1 and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.005 0.69476\n",
      "Spearman r for demo_prnt_marital_v2.baseline_year_1_arm_1 and scanner:\n",
      "\t\t\t\t\t 0.03727153729633294 0.0012858361308994391\n",
      "Spearman r for demo_prnt_marital_v2.baseline_year_1_arm_1 and F:\n",
      "\t\t\t\t\t 0.014813484593102015 0.2008765497444268\n",
      "Spearman r for demo_prnt_marital_v2.baseline_year_1_arm_1 and M:\n",
      "\t\t\t\t\t -0.014813484593102015 0.2008765497444268\n",
      "Spearman r for demo_prnt_marital_v2.baseline_year_1_arm_1 and puberty:\n",
      "\t\t\t\t\t 0.15975638148419716 8.084512664799542e-44\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.3624921157179303 2.2694551682722875e-230\n",
      "Prodcuct moment correlation for demo_prnt_ed_v2.baseline_year_1_arm_1 and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.045 0.00011\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.27233179783982203 6.088898887691965e-127\n",
      "Prodcuct moment correlation for demo_prnt_ed_v2.baseline_year_1_arm_1 and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.009 0.46078\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and scanner:\n",
      "\t\t\t\t\t -0.056945708089078985 8.625553005225117e-07\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and F:\n",
      "\t\t\t\t\t -0.01218267808260975 0.29285244598658583\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and M:\n",
      "\t\t\t\t\t 0.01218267808260975 0.29285244598658583\n",
      "Spearman r for demo_prnt_ed_v2.baseline_year_1_arm_1 and puberty:\n",
      "\t\t\t\t\t -0.10720585465397166 1.6499449488009765e-20\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.3773554097195225 5.164808151688294e-251\n",
      "Prodcuct moment correlation for demo_comb_income_v2.baseline_year_1_arm_1 and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.045 0.00011\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.22057422328803694 7.576755116367166e-83\n",
      "Prodcuct moment correlation for demo_comb_income_v2.baseline_year_1_arm_1 and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.001 0.93349\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and scanner:\n",
      "\t\t\t\t\t -0.05028999471103708 1.3942837697216154e-05\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and F:\n",
      "\t\t\t\t\t -0.023376508604008812 0.043529785649383125\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and M:\n",
      "\t\t\t\t\t 0.023376508604008812 0.043529785649383125\n",
      "Spearman r for demo_comb_income_v2.baseline_year_1_arm_1 and puberty:\n",
      "\t\t\t\t\t -0.12096175458294096 1.0420106139550215e-25\n",
      "Spearman r for race_ethnicity.baseline_year_1_arm_1 and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.25693976134628077 9.812102548232799e-113\n",
      "Prodcuct moment correlation for race_ethnicity.baseline_year_1_arm_1 and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.005 0.64366\n",
      "Prodcuct moment correlation for race_ethnicity.baseline_year_1_arm_1 and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.085 0.0\n",
      "Prodcuct moment correlation for race_ethnicity.baseline_year_1_arm_1 and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.022 0.05571\n",
      "Spearman r for race_ethnicity.baseline_year_1_arm_1 and scanner:\n",
      "\t\t\t\t\t 0.1286753267540209 6.681481875647165e-29\n",
      "Spearman r for race_ethnicity.baseline_year_1_arm_1 and F:\n",
      "\t\t\t\t\t 0.029392070275259155 0.011141046463668317\n",
      "Spearman r for race_ethnicity.baseline_year_1_arm_1 and M:\n",
      "\t\t\t\t\t -0.029392070275259155 0.011141046463668317\n",
      "Spearman r for race_ethnicity.baseline_year_1_arm_1 and puberty:\n",
      "\t\t\t\t\t 0.1267249466208394 4.478732055305326e-28\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.015878635351864977 0.17090843935306815\n",
      "Prodcuct moment correlation for interview_age.baseline_year_1_arm_1 and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.009 0.46078\n",
      "Prodcuct moment correlation for interview_age.baseline_year_1_arm_1 and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.001 0.93349\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.025982316489053497 0.025037969807779992\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and scanner:\n",
      "\t\t\t\t\t -0.05700722930937141 8.667831262121838e-07\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and F:\n",
      "\t\t\t\t\t -0.03632914064405216 0.0017263348038902722\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and M:\n",
      "\t\t\t\t\t 0.03632914064405216 0.0017263348038902722\n",
      "Spearman r for interview_age.baseline_year_1_arm_1 and puberty:\n",
      "\t\t\t\t\t 0.14902294894468002 3.366243853519235e-38\n",
      "Spearman r for scanner and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.03727153729633294 0.0012858361308994391\n",
      "Prodcuct moment correlation for scanner and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.009 0.44492\n",
      "Prodcuct moment correlation for scanner and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.007 0.53027\n",
      "Spearman r for scanner and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.1286753267540209 6.681481875647165e-29\n",
      "Prodcuct moment correlation for scanner and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.053 0.0\n",
      "Spearman r for scanner and F:\n",
      "\t\t\t\t\t 0.015235511338979931 0.18834125887129372\n",
      "Spearman r for scanner and M:\n",
      "\t\t\t\t\t -0.015235511338979931 0.18834125887129372\n",
      "Spearman r for scanner and puberty:\n",
      "\t\t\t\t\t -0.004376010006716011 0.7055612762929957\n",
      "Spearman r for F and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.014813484593102015 0.2008765497444268\n",
      "Point biserial r for F and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.013 0.26874\n",
      "Point biserial r for F and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.012 0.30377\n",
      "Spearman r for F and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.02939207027525916 0.011141046463668317\n",
      "Point biserial r for F and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.036 0.00191\n",
      "Spearman r for F and scanner:\n",
      "\t\t\t\t\t 0.015235511338979931 0.18834125887129372\n",
      "Chi^2 for F and M:\n",
      "\t\t\t\t\t 7457.0 0.49456\n",
      "Spearman r for F and puberty:\n",
      "\t\t\t\t\t 0.4262673464916116 0.0\n",
      "Spearman r for M and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.014813484593102015 0.2008765497444268\n",
      "Point biserial r for M and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.013 0.26874\n",
      "Point biserial r for M and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.012 0.30377\n",
      "Spearman r for M and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t -0.02939207027525916 0.011141046463668317\n",
      "Point biserial r for M and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.036 0.00191\n",
      "Spearman r for M and scanner:\n",
      "\t\t\t\t\t -0.015235511338979931 0.18834125887129372\n",
      "Chi^2 for M and F:\n",
      "\t\t\t\t\t 7457.0 0.49456\n",
      "Spearman r for M and puberty:\n",
      "\t\t\t\t\t -0.4262673464916116 0.0\n",
      "Spearman r for puberty and demo_prnt_marital_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.15975638148419713 8.084512664799541e-44\n",
      "Prodcuct moment correlation for puberty and demo_prnt_ed_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.001 0.92771\n",
      "Prodcuct moment correlation for puberty and demo_comb_income_v2.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.02 0.08963\n",
      "Spearman r for puberty and race_ethnicity.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.1267249466208394 4.478732055305326e-28\n",
      "Prodcuct moment correlation for puberty and interview_age.baseline_year_1_arm_1:\n",
      "\t\t\t\t\t 0.151 0.0\n",
      "Spearman r for puberty and scanner:\n",
      "\t\t\t\t\t -0.004376010006716011 0.7055612762929957\n",
      "Spearman r for puberty and F:\n",
      "\t\t\t\t\t 0.4262673464916116 0.0\n",
      "Spearman r for puberty and M:\n",
      "\t\t\t\t\t -0.4262673464916116 0.0\n"
     ]
    }
   ],
   "source": [
    "meas = ['stat', 'p']\n",
    "index = pd.MultiIndex.from_product([meas, coll_df.columns])\n",
    "correlations = pd.DataFrame(columns=coll_df.columns, index=index)\n",
    "\n",
    "for var in coll_df.columns:\n",
    "    for var1 in coll_df.columns:\n",
    "        temp = coll_df[[var, var1]].dropna()\n",
    "        if var != var1:\n",
    "            if len(np.unique(temp[var])) <= 2:\n",
    "                if len(np.unique(temp[var1])) > 2:\n",
    "                    if len(np.unique(temp[var1])) <= 10:\n",
    "                        r,p = sstats.spearmanr(temp[var], temp[var1])\n",
    "                        print(f'Spearman r for {var} and {var1}:\\n\\t\\t\\t\\t\\t', r,p)\n",
    "                        correlations.at[(var, 'stat'), var1] = r\n",
    "                        correlations.at[(var, 'p'), var1] = p\n",
    "                    else:\n",
    "                        r,p = sstats.pointbiserialr(temp[var], temp[var1])\n",
    "                        correlations.at[(var, 'stat'), var1] = r\n",
    "                        correlations.at[(var, 'p'), var1] = p\n",
    "                        print(f'Point biserial r for {var} and {var1}:\\n\\t\\t\\t\\t\\t', \n",
    "                              np.round(r, 3), np.round(p, 5))\n",
    "                else:\n",
    "                    chi2 = sstats.contingency.chi2_contingency(temp[[var,var1]].values)\n",
    "                    print(f'Chi^2 for {var} and {var1}:\\n\\t\\t\\t\\t\\t', \n",
    "                          np.round(chi2[0], 3), np.round(chi2[1], 5))\n",
    "                    correlations.at[(var, 'stat'), var1] = chi2[0]\n",
    "                    correlations.at[(var, 'p'), var1] = chi2[1]\n",
    "            else:\n",
    "                \n",
    "                if len(np.unique(temp[var1])) > 10:\n",
    "                    r,p = sstats.pearsonr(temp[var1], temp[var])\n",
    "                    correlations.at[(var, 'stat'), var1] = r\n",
    "                    correlations.at[(var, 'p'), var1] = p\n",
    "                    print(f'Prodcuct moment correlation for {var} and {var1}:\\n\\t\\t\\t\\t\\t', \n",
    "                          np.round(r, 3), np.round(p, 5))\n",
    "                elif len(np.unique(temp[var1])) < 2:\n",
    "                    r,p = sstats.pointbiserialr(temp[var], temp[var1])\n",
    "                    print(f'Point biserial r for {var} and {var1}:\\n\\t\\t\\t\\t\\t', \n",
    "                          np.round(r, 3), np.round(p, 5))\n",
    "                    correlations.at[(var, 'stat'), var1] = r\n",
    "                    correlations.at[(var, 'p'), var1] = p\n",
    "                else:\n",
    "                    r,p = sstats.spearmanr(temp[var].astype(int), temp[var1].astype(int))\n",
    "                    print(f'Spearman r for {var} and {var1}:\\n\\t\\t\\t\\t\\t', r,p)\n",
    "                    correlations.at[(var, 'stat'), var1] = r\n",
    "                    correlations.at[(var, 'p'), var1] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3dd29931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">demo_prnt_marital_v2.baseline_year_1_arm_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">demo_prnt_ed_v2.baseline_year_1_arm_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">demo_comb_income_v2.baseline_year_1_arm_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">race_ethnicity.baseline_year_1_arm_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">interview_age.baseline_year_1_arm_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">scanner</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F</th>\n",
       "      <th colspan=\"2\" halign=\"left\">M</th>\n",
       "      <th colspan=\"2\" halign=\"left\">puberty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "      <th>stat</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>demo_prnt_marital_v2.baseline_year_1_arm_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.362492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.377355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015879</td>\n",
       "      <td>0.170908</td>\n",
       "      <td>0.037272</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>-0.014813</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo_prnt_ed_v2.baseline_year_1_arm_1</th>\n",
       "      <td>-0.013474</td>\n",
       "      <td>0.244657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044765</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.643664</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.460781</td>\n",
       "      <td>-0.008848</td>\n",
       "      <td>0.444922</td>\n",
       "      <td>-0.012809</td>\n",
       "      <td>0.268738</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.268738</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.927706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo_comb_income_v2.baseline_year_1_arm_1</th>\n",
       "      <td>0.08638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044765</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.933491</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>0.530267</td>\n",
       "      <td>-0.011911</td>\n",
       "      <td>0.303765</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.303765</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>0.089632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_ethnicity.baseline_year_1_arm_1</th>\n",
       "      <td>0.25694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>0.128675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.126725</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interview_age.baseline_year_1_arm_1</th>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.694762</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.460781</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.933491</td>\n",
       "      <td>-0.022186</td>\n",
       "      <td>0.055712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053356</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.035989</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.035989</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.151435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scanner</th>\n",
       "      <td>0.037272</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.05029</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.128675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.057007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.188341</td>\n",
       "      <td>-0.015236</td>\n",
       "      <td>0.188341</td>\n",
       "      <td>-0.004376</td>\n",
       "      <td>0.705561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>-0.012183</td>\n",
       "      <td>0.292852</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>0.04353</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>-0.036329</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.188341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7457.0</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>0.426267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>-0.014813</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.292852</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.04353</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.036329</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>-0.015236</td>\n",
       "      <td>0.188341</td>\n",
       "      <td>7457.0</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.426267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puberty</th>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.107206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004376</td>\n",
       "      <td>0.705561</td>\n",
       "      <td>0.426267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.426267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           demo_prnt_marital_v2.baseline_year_1_arm_1  \\\n",
       "                                                                                 stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1                                        NaN   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1                                       -0.013474   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1                                     0.08638   \n",
       "race_ethnicity.baseline_year_1_arm_1                                          0.25694   \n",
       "interview_age.baseline_year_1_arm_1                                          0.004551   \n",
       "scanner                                                                      0.037272   \n",
       "F                                                                            0.014813   \n",
       "M                                                                           -0.014813   \n",
       "puberty                                                                      0.159756   \n",
       "\n",
       "                                                      \\\n",
       "                                                   p   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1       NaN   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1       0.244657   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1        0.0   \n",
       "race_ethnicity.baseline_year_1_arm_1             0.0   \n",
       "interview_age.baseline_year_1_arm_1         0.694762   \n",
       "scanner                                     0.001286   \n",
       "F                                           0.200877   \n",
       "M                                           0.200877   \n",
       "puberty                                          0.0   \n",
       "\n",
       "                                           demo_prnt_ed_v2.baseline_year_1_arm_1  \\\n",
       "                                                                            stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1                             -0.362492   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1                                        NaN   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1                               0.044765   \n",
       "race_ethnicity.baseline_year_1_arm_1                                   -0.272332   \n",
       "interview_age.baseline_year_1_arm_1                                     0.008553   \n",
       "scanner                                                                -0.056946   \n",
       "F                                                                      -0.012183   \n",
       "M                                                                       0.012183   \n",
       "puberty                                                                -0.107206   \n",
       "\n",
       "                                                      \\\n",
       "                                                   p   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1       0.0   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1            NaN   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1    0.00011   \n",
       "race_ethnicity.baseline_year_1_arm_1             0.0   \n",
       "interview_age.baseline_year_1_arm_1         0.460781   \n",
       "scanner                                     0.000001   \n",
       "F                                           0.292852   \n",
       "M                                           0.292852   \n",
       "puberty                                          0.0   \n",
       "\n",
       "                                           demo_comb_income_v2.baseline_year_1_arm_1  \\\n",
       "                                                                                stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1                                 -0.377355   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1                                       0.044765   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1                                        NaN   \n",
       "race_ethnicity.baseline_year_1_arm_1                                       -0.220574   \n",
       "interview_age.baseline_year_1_arm_1                                        -0.000968   \n",
       "scanner                                                                     -0.05029   \n",
       "F                                                                          -0.023377   \n",
       "M                                                                           0.023377   \n",
       "puberty                                                                    -0.120962   \n",
       "\n",
       "                                                      \\\n",
       "                                                   p   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1       0.0   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1        0.00011   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1        NaN   \n",
       "race_ethnicity.baseline_year_1_arm_1             0.0   \n",
       "interview_age.baseline_year_1_arm_1         0.933491   \n",
       "scanner                                     0.000014   \n",
       "F                                            0.04353   \n",
       "M                                            0.04353   \n",
       "puberty                                          0.0   \n",
       "\n",
       "                                           race_ethnicity.baseline_year_1_arm_1  \\\n",
       "                                                                           stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1                              0.25694   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1                                  0.005358   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1                              0.084855   \n",
       "race_ethnicity.baseline_year_1_arm_1                                        NaN   \n",
       "interview_age.baseline_year_1_arm_1                                   -0.022186   \n",
       "scanner                                                                0.128675   \n",
       "F                                                                      0.029392   \n",
       "M                                                                     -0.029392   \n",
       "puberty                                                                0.126725   \n",
       "\n",
       "                                                      \\\n",
       "                                                   p   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1       0.0   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1       0.643664   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1        0.0   \n",
       "race_ethnicity.baseline_year_1_arm_1             NaN   \n",
       "interview_age.baseline_year_1_arm_1         0.055712   \n",
       "scanner                                          0.0   \n",
       "F                                           0.011141   \n",
       "M                                           0.011141   \n",
       "puberty                                          0.0   \n",
       "\n",
       "                                           interview_age.baseline_year_1_arm_1  \\\n",
       "                                                                          stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1                           -0.015879   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1                                 0.008553   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1                            -0.000968   \n",
       "race_ethnicity.baseline_year_1_arm_1                                 -0.025982   \n",
       "interview_age.baseline_year_1_arm_1                                        NaN   \n",
       "scanner                                                              -0.057007   \n",
       "F                                                                    -0.036329   \n",
       "M                                                                     0.036329   \n",
       "puberty                                                               0.149023   \n",
       "\n",
       "                                                       scanner            \\\n",
       "                                                   p      stat         p   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1  0.170908  0.037272  0.001286   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1       0.460781 -0.008848  0.444922   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1   0.933491  0.007269  0.530267   \n",
       "race_ethnicity.baseline_year_1_arm_1        0.025038  0.128675       0.0   \n",
       "interview_age.baseline_year_1_arm_1              NaN -0.053356  0.000004   \n",
       "scanner                                     0.000001       NaN       NaN   \n",
       "F                                           0.001726  0.015236  0.188341   \n",
       "M                                           0.001726 -0.015236  0.188341   \n",
       "puberty                                          0.0 -0.004376  0.705561   \n",
       "\n",
       "                                                   F                   M  \\\n",
       "                                                stat         p      stat   \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1  0.014813  0.200877 -0.014813   \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1      -0.012809  0.268738  0.012809   \n",
       "demo_comb_income_v2.baseline_year_1_arm_1  -0.011911  0.303765  0.011911   \n",
       "race_ethnicity.baseline_year_1_arm_1        0.029392  0.011141 -0.029392   \n",
       "interview_age.baseline_year_1_arm_1        -0.035989  0.001907  0.035989   \n",
       "scanner                                     0.015236  0.188341 -0.015236   \n",
       "F                                                NaN       NaN    7457.0   \n",
       "M                                             7457.0  0.494555       NaN   \n",
       "puberty                                     0.426267       0.0 -0.426267   \n",
       "\n",
       "                                                       puberty            \n",
       "                                                   p      stat         p  \n",
       "demo_prnt_marital_v2.baseline_year_1_arm_1  0.200877  0.159756       0.0  \n",
       "demo_prnt_ed_v2.baseline_year_1_arm_1       0.268738  0.001051  0.927706  \n",
       "demo_comb_income_v2.baseline_year_1_arm_1   0.303765  0.019657  0.089632  \n",
       "race_ethnicity.baseline_year_1_arm_1        0.011141  0.126725       0.0  \n",
       "interview_age.baseline_year_1_arm_1         0.001907  0.151435       0.0  \n",
       "scanner                                     0.188341 -0.004376  0.705561  \n",
       "F                                           0.494555  0.426267       0.0  \n",
       "M                                                NaN -0.426267       0.0  \n",
       "puberty                                          0.0       NaN       NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations.dropna(how='all').T.to_csv(join(PROJ_DIR, OUT_DIR, 'pairwise_correlations_devt+demo.csv'))\n",
    "correlations.dropna(how='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740056a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Of the total {total_N} participants at baseline, {lost_N} (or {np.round((lost_N / total_N) *100, 2)}%) did not have a 2-year follow-up imaging appointment and were, thus, excluded from further analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean_base',\n",
    "                            'Age_sdev_base',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F', \n",
    "                            'RE_Black',\n",
    "                            'RE_White',\n",
    "                            'RE_Hispanic',\n",
    "                            'RE_Asian',\n",
    "                            'RE_Other',\n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse',\n",
    "                            'Marital_Married',\n",
    "                            'Marital_Widowed',\n",
    "                            'Marital_Divorced',\n",
    "                            'Marital_Separated',\n",
    "                            'Marital_Never',\n",
    "                            'Marital_Refused',\n",
    "                            'Education_ltHS',\n",
    "                            'Education_HSGED',\n",
    "                            'Education_SomeCol',\n",
    "                            'Education_AA',\n",
    "                            'Education_Bachelors',\n",
    "                            'Education_Graduate',\n",
    "                            'MRI_Siemens', \n",
    "                            'MRI_GE', \n",
    "                            'MRI_Phillips'], \n",
    "                     columns=['whole_sample', 'with_2yfu'])\n",
    "\n",
    "table.at['N', 'whole_sample'] = len(demo_df.index)\n",
    "table.at['N', 'with_2yfu'] = len(y2fu_df.index)\n",
    "\n",
    "table.at['Age_mean_base', 'whole_sample'] = np.mean(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean_base', 'with_2yfu'] = np.mean(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_mean_2yfu', 'whole_sample'] = np.mean(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_mean_2yfu', 'with_2yfu'] = np.mean(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_base', 'whole_sample'] = np.std(demo_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev_base', 'with_2yfu'] = np.std(y2fu_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev_2yfu', 'whole_sample'] = np.std(demo_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "table.at['Age_sdev_2yfu', 'with_2yfu'] = np.std(y2fu_df['interview_age.2_year_follow_up_y_arm_1'])\n",
    "\n",
    "table.at['Sex_M', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_F', 'whole_sample'] = len(demo_df[demo_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'with_2yfu'] = len(y2fu_df[y2fu_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "\n",
    "table.at['RE_White', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_Black', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'whole_sample'] = len(demo_df[demo_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['MRI_Siemens', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_Siemens', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_GE', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1']  == \"GE MEDICAL SYSTEMS\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'whole_sample'] = len(demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "table.at['MRI_Philips', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"].index)\n",
    "\n",
    "table.at['Marital_Married', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Widowed', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Divorced', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Separated', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Never', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Refused', \n",
    "         'whole_sample'] = len(demo_df[demo_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'whole_sample'] = len(demo_df[demo_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_uptoHSGED', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'with_2yfu'] = len(y2fu_df[y2fu_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39717e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'].dropna())\n",
    "table.at['Age_mean_base', 'Stat'] = stat\n",
    "table.at['Age_mean_base', 'p(Stat)'] = pval\n",
    "\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.2_year_follow_up_y_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.2_year_follow_up_y_arm_1'].dropna())\n",
    "table.at['Age_mean_2yfu', 'Stat'] = stat\n",
    "table.at['Age_mean_2yfu', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((2,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Sex_F', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Sex_M', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Sex_F', 'with_2yfu']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['RE_White', 'whole_sample']\n",
    "contingency[0,1] = table.loc['RE_Black', 'whole_sample']\n",
    "contingency[0,2] = table.loc['RE_Hispanic', 'whole_sample']\n",
    "contingency[0,3] = table.loc['RE_AsianOther', 'whole_sample']\n",
    "contingency[1,0] = table.loc['RE_White', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['RE_Black', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['RE_Hispanic', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['RE_AsianOther', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['RE_White', 'Stat'] = out.statistic\n",
    "table.at['RE_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,3))\n",
    "contingency[0,0] = table.loc['MRI_Siemens', 'whole_sample']\n",
    "contingency[0,1] = table.loc['MRI_GE', 'whole_sample']\n",
    "contingency[0,2] = table.loc['MRI_Philips', 'whole_sample']\n",
    "contingency[1,0] = table.loc['MRI_Siemens', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['MRI_GE', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['MRI_Philips', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['MRI_Siemens', 'Stat'] = out.statistic\n",
    "table.at['MRI_Siemens', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,5))\n",
    "contingency[0,0] = table.loc['Marital_Married', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Marital_Widowed', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Marital_Divorced', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Marital_Separated', 'whole_sample']\n",
    "contingency[0,4] = table.loc['Marital_Never', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Marital_Married', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Marital_Widowed', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Marital_Divorced', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Marital_Separated', 'with_2yfu']\n",
    "contingency[1,4] = table.loc['Marital_Never', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Marital_Married', 'Stat'] = out.statistic\n",
    "table.at['Marital_Married', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((2,4))\n",
    "contingency[0,0] = table.loc['Education_uptoHSGED', 'whole_sample']\n",
    "contingency[0,1] = table.loc['Education_SomeColAA', 'whole_sample']\n",
    "contingency[0,2] = table.loc['Education_Bachelors', 'whole_sample']\n",
    "contingency[0,3] = table.loc['Education_Graduate', 'whole_sample']\n",
    "contingency[1,0] = table.loc['Education_uptoHSGED', 'with_2yfu']\n",
    "contingency[1,1] = table.loc['Education_SomeColAA', 'with_2yfu']\n",
    "contingency[1,2] = table.loc['Education_Bachelors', 'with_2yfu']\n",
    "contingency[1,3] = table.loc['Education_Graduate', 'with_2yfu']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Education_uptoHSGED', 'Stat'] = out.statistic\n",
    "table.at['Education_uptoHSGED', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(join(PROJ_DIR, OUT_DIR, 'sample_demographics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a40f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same thing for Siemens vs. GE vs. Philips\n",
    "\n",
    "table = pd.DataFrame(index=['N', \n",
    "                            'Age_mean',\n",
    "                            'Age_sdev',\n",
    "                            'Age_mean_2yfu',\n",
    "                            'Age_sdev_2yfu',\n",
    "                            'Sex_M', \n",
    "                            'Sex_F',\n",
    "                            'Puberty',\n",
    "                            'RE_Black',\n",
    "                            'RE_White',\n",
    "                            'RE_Hispanic',\n",
    "                            'RE_Asian',\n",
    "                            'RE_Other',\n",
    "                            'Income_gt100k', \n",
    "                            'Income_50to100k', \n",
    "                            'Income_lt50k',\n",
    "                            'Income_dkrefuse',\n",
    "                            'Marital_Married',\n",
    "                            'Marital_Widowed',\n",
    "                            'Marital_Divorced',\n",
    "                            'Marital_Separated',\n",
    "                            'Marital_Never',\n",
    "                            'Marital_Refused',\n",
    "                            'Education_ltHS',\n",
    "                            'Education_HSGED',\n",
    "                            'Education_SomeCol',\n",
    "                            'Education_AA',\n",
    "                            'Education_Bachelors',\n",
    "                            'Education_Graduate'], \n",
    "                     columns=['siemens', 'philips', 'ge'])\n",
    "\n",
    "philips_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"Philips Medical Systems\"]\n",
    "siemens_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"SIEMENS\"]\n",
    "ge_df = demo_df[demo_df['mri_info_manufacturer.baseline_year_1_arm_1'] == \"GE MEDICAL SYSTEMS\"]\n",
    "\n",
    "\n",
    "table.at['N', 'philips'] = len(philips_df.index)\n",
    "table.at['N', 'siemens'] = len(siemens_df.index)\n",
    "table.at['N', 'ge'] = len(ge_df.index)\n",
    "\n",
    "table.at['Age_mean', 'philips'] = np.mean(philips_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean', 'siemens'] = np.mean(siemens_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_mean', 'ge'] = np.mean(ge_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "table.at['Age_sdev', 'philips'] = np.std(philips_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev', 'siemens'] = np.std(siemens_df['interview_age.baseline_year_1_arm_1'])\n",
    "table.at['Age_sdev', 'ge'] = np.std(ge_df['interview_age.baseline_year_1_arm_1'])\n",
    "\n",
    "\n",
    "table.at['Sex_M', 'philips'] = len(philips_df[philips_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'siemens'] = len(siemens_df[siemens_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "table.at['Sex_M', 'ge'] = len(ge_df[ge_df['sex.baseline_year_1_arm_1'] == 'M'].index)\n",
    "\n",
    "table.at['Sex_F', 'philips'] = len(philips_df[philips_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'siemens'] = len(siemens_df[siemens_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "table.at['Sex_F', 'ge'] = len(ge_df[ge_df['sex.baseline_year_1_arm_1'] == 'F'].index)\n",
    "\n",
    "\n",
    "table.at['RE_White', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_White', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 1.].index)\n",
    "table.at['RE_Black', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "table.at['RE_Black', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 2.].index)\n",
    "\n",
    "table.at['RE_Hispanic', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "table.at['RE_Hispanic', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'] == 3.].index)\n",
    "\n",
    "table.at['RE_AsianOther', \n",
    "         'philips'] = len(philips_df[philips_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'siemens'] = len(siemens_df[siemens_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "table.at['RE_AsianOther', \n",
    "         'ge'] = len(ge_df[ge_df['race_ethnicity.baseline_year_1_arm_1'].between(4.,5.,inclusive='both')].index)\n",
    "\n",
    "\n",
    "table.at['Income_gt100k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "table.at['Income_gt100k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(9.,10., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_50to100k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "table.at['Income_50to100k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'].between(7., 8., inclusive='both')].index)\n",
    "\n",
    "table.at['Income_lt50k', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "table.at['Income_lt50k', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'] <= 6.].index)\n",
    "\n",
    "table.at['Income_dkrefuse', \n",
    "         'philips'] = len(philips_df[philips_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "table.at['Income_dkrefuse', \n",
    "         'ge'] = len(ge_df[ge_df['demo_comb_income_v2.baseline_year_1_arm_1'] >= 777.].index)\n",
    "\n",
    "table.at['Marital_Married', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "table.at['Marital_Married', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 1.])\n",
    "\n",
    "table.at['Marital_Widowed', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "table.at['Marital_Widowed', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 2.])\n",
    "\n",
    "table.at['Marital_Divorced', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "table.at['Marital_Divorced', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 3.])\n",
    "\n",
    "table.at['Marital_Separated', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "table.at['Marital_Separated', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 4.])\n",
    "\n",
    "table.at['Marital_Never', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "table.at['Marital_Never', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 5.])\n",
    "\n",
    "table.at['Marital_Refused', \n",
    "         'philips'] = len(philips_df[philips_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'siemens'] = len(siemens_df[siemens_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "table.at['Marital_Refused', \n",
    "         'ge'] = len(ge_df[ge_df[\"demo_prnt_marital_v2.baseline_year_1_arm_1\"] == 777.])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'philips'] = len(philips_df[philips_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_uptoHSGED', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'siemens'] = len(siemens_df[siemens_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])\n",
    "\n",
    "table.at['Education_uptoHSGED', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(0,14, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_SomeColAA', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(15,17, \n",
    "                                                                                                inclusive='both')])\n",
    "table.at['Education_Bachelors', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'] == 18])\n",
    "table.at['Education_Graduate', \n",
    "         'ge'] = len(ge_df[ge_df['demo_prnt_ed_v2.baseline_year_1_arm_1'].between(19,22, \n",
    "                                                                                                inclusive='both')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for differences in means with wilcoxon signed rank test\n",
    "stat, pval = sstats.mannwhitneyu(demo_df['interview_age.baseline_year_1_arm_1'].dropna(), \n",
    "                                 y2fu_df['interview_age.baseline_year_1_arm_1'].dropna())\n",
    "table.at['Age_mean', 'Stat'] = stat\n",
    "table.at['Age_mean', 'p(Stat)'] = pval\n",
    "\n",
    "contingency = np.zeros((3,2))\n",
    "contingency[0,0] = table.loc['Sex_M', 'philips']\n",
    "contingency[0,1] = table.loc['Sex_F', 'philips']\n",
    "contingency[1,0] = table.loc['Sex_M', 'siemens']\n",
    "contingency[1,1] = table.loc['Sex_F', 'siemens']\n",
    "contingency[2,0] = table.loc['Sex_M', 'ge']\n",
    "contingency[2,1] = table.loc['Sex_F', 'ge']\n",
    "out = contingency_tables.mcnemar(contingency) \n",
    "table.at['Sex_M', 'Stat'] = out.statistic\n",
    "table.at['Sex_M', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['RE_White', 'philips']\n",
    "contingency[0,1] = table.loc['RE_Black', 'philips']\n",
    "contingency[0,2] = table.loc['RE_Hispanic', 'philips']\n",
    "contingency[0,3] = table.loc['RE_AsianOther', 'philips']\n",
    "contingency[1,0] = table.loc['RE_White', 'siemens']\n",
    "contingency[1,1] = table.loc['RE_Black', 'siemens']\n",
    "contingency[1,2] = table.loc['RE_Hispanic', 'siemens']\n",
    "contingency[1,3] = table.loc['RE_AsianOther', 'siemens']\n",
    "contingency[2,0] = table.loc['RE_White', 'ge']\n",
    "contingency[2,1] = table.loc['RE_Black', 'ge']\n",
    "contingency[2,2] = table.loc['RE_Hispanic', 'ge']\n",
    "contingency[2,3] = table.loc['RE_AsianOther', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['RE_White', 'Stat'] = out.statistic\n",
    "table.at['RE_White', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['Income_gt100k', 'philips']\n",
    "contingency[0,1] = table.loc['Income_50to100k', 'philips']\n",
    "contingency[0,2] = table.loc['Income_lt50k', 'philips']\n",
    "contingency[0,3] = table.loc['Income_dkrefuse', 'philips']\n",
    "contingency[1,0] = table.loc['Income_gt100k', 'siemens']\n",
    "contingency[1,1] = table.loc['Income_50to100k', 'siemens']\n",
    "contingency[1,2] = table.loc['Income_lt50k', 'siemens']\n",
    "contingency[1,3] = table.loc['Income_dkrefuse', 'siemens']\n",
    "contingency[2,0] = table.loc['Income_gt100k', 'ge']\n",
    "contingency[2,1] = table.loc['Income_50to100k', 'ge']\n",
    "contingency[2,2] = table.loc['Income_lt50k', 'ge']\n",
    "contingency[2,3] = table.loc['Income_dkrefuse', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Income_gt100k', 'Stat'] = out.statistic\n",
    "table.at['Income_gt100k', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "\n",
    "contingency = np.zeros((3,5))\n",
    "contingency[0,0] = table.loc['Marital_Married', 'philips']\n",
    "contingency[0,1] = table.loc['Marital_Widowed', 'philips']\n",
    "contingency[0,2] = table.loc['Marital_Divorced', 'philips']\n",
    "contingency[0,3] = table.loc['Marital_Separated', 'philips']\n",
    "contingency[0,4] = table.loc['Marital_Never', 'philips']\n",
    "contingency[1,0] = table.loc['Marital_Married', 'siemens']\n",
    "contingency[1,1] = table.loc['Marital_Widowed', 'siemens']\n",
    "contingency[1,2] = table.loc['Marital_Divorced', 'siemens']\n",
    "contingency[1,3] = table.loc['Marital_Separated', 'siemens']\n",
    "contingency[1,4] = table.loc['Marital_Never', 'siemens']\n",
    "contingency[2,0] = table.loc['Marital_Married', 'ge']\n",
    "contingency[2,1] = table.loc['Marital_Widowed', 'ge']\n",
    "contingency[2,2] = table.loc['Marital_Divorced', 'ge']\n",
    "contingency[2,3] = table.loc['Marital_Separated', 'ge']\n",
    "contingency[2,4] = table.loc['Marital_Never', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Marital_Married', 'Stat'] = out.statistic\n",
    "table.at['Marital_Married', 'p(Stat)'] = out.pvalue\n",
    "\n",
    "contingency = np.zeros((3,4))\n",
    "contingency[0,0] = table.loc['Education_uptoHSGED', 'philips']\n",
    "contingency[0,1] = table.loc['Education_SomeColAA', 'philips']\n",
    "contingency[0,2] = table.loc['Education_Bachelors', 'philips']\n",
    "contingency[0,3] = table.loc['Education_Graduate', 'philips']\n",
    "contingency[1,0] = table.loc['Education_uptoHSGED', 'siemens']\n",
    "contingency[1,1] = table.loc['Education_SomeColAA', 'siemens']\n",
    "contingency[1,2] = table.loc['Education_Bachelors', 'siemens']\n",
    "contingency[1,3] = table.loc['Education_Graduate', 'siemens']\n",
    "contingency[2,0] = table.loc['Education_uptoHSGED', 'ge']\n",
    "contingency[2,1] = table.loc['Education_SomeColAA', 'ge']\n",
    "contingency[2,2] = table.loc['Education_Bachelors', 'ge']\n",
    "contingency[2,3] = table.loc['Education_Graduate', 'ge']\n",
    "out = contingency_tables.cochrans_q(contingency) \n",
    "table.at['Education_uptoHSGED', 'Stat'] = out.statistic\n",
    "table.at['Education_uptoHSGED', 'p(Stat)'] = out.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec36d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ba7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(join(PROJ_DIR, OUT_DIR, 'demographic_differences_between_scanners.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de277b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
